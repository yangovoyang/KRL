def sort_by_head(param_list): # h, r, t
    for i in range(len(param_list)-1):  # 0, n-2
        for j in range(len(param_list)-i-1):  # i n-2-i
            if (param_list[j][0] > param_list[j+1][0]) or (param_list[j][0] == param_list[j+1][0] and param_list[j][1] > param_list[j+1][1]) or (param_list[j][0] == param_list[j+1][0] and param_list[j][1] == param_list[j+1][1] and param_list[j][2] > param_list[j+1][2]):
                param_list[j], param_list[j + 1] = param_list[j + 1], param_list[j]


def sort_by_relation(param_list):  # h, t, r
    for i in range(len(param_list)-1):  # 0, n-2
        for j in range(len(param_list)-i-1):  # i n-2-i
            if (param_list[j][0] > param_list[j+1][0]) or (param_list[j][0] == param_list[j+1][0] and param_list[j][2] > param_list[j+1][2]) or (param_list[j][0] == param_list[j+1][0] and param_list[j][2] == param_list[j+1][2] and param_list[j][1] > param_list[j+1][1]):
                param_list[j], param_list[j + 1] = param_list[j + 1], param_list[j]


def sort_by_tail(param_list):  # t, r, h
    for i in range(len(param_list)-1):  # 0, n-2
        for j in range(len(param_list)-i-1):  # i n-2-i
            if (param_list[j][2] > param_list[j+1][2]) or (param_list[j][2] == param_list[j+1][2] and param_list[j][1] > param_list[j+1][1]) or (param_list[j][2] == param_list[j+1][2] and param_list[j][1] == param_list[j+1][1] and param_list[j][0] > param_list[j+1][0]):
                param_list[j], param_list[j + 1] = param_list[j + 1], param_list[j]


def import_train_files():
	print('The toolkit is importing datasets.')

	entity_total = 0
	relation_total = 0
    with open(dataset_path + 'relation2id.txt', 'r', encoding='utf8') as file:
		relation_total = int(file.readline())
        print('The total of relations is', relation_total)

    with open(dataset_path + 'entity2id.txt', 'r', encoding='utf8') as file:
		entity_total = int(file.readline())
        print('The total of entities is', entity_total)

    train_list = []
    with open(dataset_path + 'train2id.txt', 'r', encoding='utf8') as file:
        train_total = int(file.readline())
        for line in file.readlines():
            temp_list = line.strip().split()
            for index in range(len(temp_list)):
                temp_list[index] = int(temp_list[index])
            train_list.append(temp_list)

    sort_by_head(train_list)

    # remove duplicate, construct three list (train_head, train_tail, train_relation) from train_list
    train_head = [[0]*3]*train_total
    train_tail = [[0]*3]*train_total
    train_relation = [[0]*3]*train_total
    frequent_entity = [0]*train_total  # entity frequency
    frequent_relation = [0]*train_total  # relation frequency
    train_head[0] = train_tail[0] = train_relation[0] = train_list[0]
    frequent_entity[train_list[0][0]] += 1
    frequent_entity[train_list[0][2]] += 1
    frequent_relation[train_list[0][0]] += 1

    index = 1  # unique index
    for i in range(1, train_total):  # 1, train_total-1
        if (train_list[i][0]!=train_list[i-1][0]) or (train_list[i][1]!=train_list[i-1][0]) or (train_list[i][2]!=train_list[i-1][2]):
            train_head[index] = train_tail[index] = train_relation[index] = train_list[index] = train_list[i]
            index += 1
            frequent_entity[train_list[i][0]] += 1
            frequent_entity[train_list[i][2]] += 1
            frequent_relation[train_list[i][1]] += 1

    sort_by_head(train_head)
    sort_by_tail(train_tail)
    sort_by_relation(train_relation)
    print('The total of train triples is', index)
	
	# construct left_head, right_head, left_tail, right_tail
	left_head = [0]*entity_total
	right_head = [-1]*entity_total
	left_tail = [0]*entity_total
	right_tail = [-1]*entity_total
	left_relation = [0]*relation_total
	right_relation = [-1]*relation_total

	# ??
	for i in range(1, train_total):
		if train_tail[i][2] != train_tail[i-1][2]:
			right_tail[train_tail[i-1][2]] = i-1
			left_tail[train_tail[i][2]] = i
		if train_head[i][0] != train_head[i-1][0]:
			right_head[train_head[i-1][0]] = i-1
			left_head[train_head[i][0]] = i
		if train_relation[i][0] != train_relation[i-1][0]:
			right_relation[train_relation[i-1][0] = i-1
			left_relation[train_relation[i][0]] = i
	# ??
	left_head[train_head[0][0]] = 0
	right_head[train_head[train_total-1][0]] = train_total - 1
	left_tail[train_tail[0][2]] = 0
	right_tail[train_tail[train_total-1][2]] = train_total - 1
	left_relation[train_relation[0][0]] = 0
	left_relation[train_relation[train_total-1][0]] = train_total - 1
	
	left_mean = [0]*relation_total
	right_mean = [0]*relation_total
	for i in range(entity_total):
		for j in range(left_head[i]+1, right_head[i]+1):
			if train_head[j][1] != train_head[j-1][1]:
				left_mean[train_head[j][1]] += 1.0
		if left_head[i]<=right_head[i]:
			left_mean[train_head[left_head[i][1]] += 1.0
		for j in range(left_tail[i]+1, right_tail[i]+1):
			if train_tail[j][1] != train_tail[j-1][1]:
				right_mean[train_tail[j][1]] += 1.0
		if left_tail[i]<=right_tail[i]:
			right_mean[train_tail[left_tail[i]][1]] += 1.0
	
	for i in range(relation_total):
		left_mean[i] = frequent_relation[i]/left_mean[i]
		right_mean[i] = frequent_relation[i]/right_mean[i]
		

if __name__ == '__main__':
    # parameters
    dataset_path = "benchmarks/heart/"  # in_path
    test_link_prediction = True
    test_triple_classification = True
    train_times = 1000
    n_batches = 100
    learning_rate = 0.001
    margin = 1
    unif_bern = 0
    entity_neg_rate = 1
    relation_neg_rate = 0
    optimizer_method = "SGD"
    # model store
    model_export_file = "/res/model.vec.tf"
    # store model's parameters
    model_parameters_file = "/res/embedding.json"

    # prepare for train and test
    import_train_files()
	entity_total = get_relation_total()
	train_total = get_train_total()
	test_total = get_test_total()
	valid_total = get_valid_total()
	batch_size = int(get_train_total()/nbatches)
	batch_seq_size = batch_size() * (1 + negative_entity + negative_relation)
	batch_head = np.zeros(batch_size * (1 + negative_entity + negative_relation), dtype=np.int64)
	batch_tail = np.zeros(self.batch_size * (1 + self.negative_ent + self.negative_rel), dtype=np.int64)
    batch_relation = np.zeros(self.batch_size * (1 + self.negative_ent + self.negative_rel), dtype=np.int64)
	batch_y = np.zeros(self.batch_size * (1 + self.negative_ent + self.negative_rel), dtype=np.float32)
	batch_head_addr     = batch_head.__array_interface__['data'][0]
	batch_tail_addr     = batch_tail.__array_interface__['data'][0]
	batch_relation_addr = batch_relation.__array_interface__['data'][0]
	batch_y_addr        = batch_y.__array_interface__['data'][0]
	
	if test_link_prediction:
		init_test_link_prediction()
	if test_triple_classification:
		init_triple_classification()
